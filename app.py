import streamlit as st
import base64
import pandas as pd
import re
import io
import numpy as np
from datetime import datetime, timedelta
import PyPDF2
from openpyxl import load_workbook
from openpyxl.worksheet.datavalidation import DataValidation
from openpyxl.utils import get_column_letter
from sqlalchemy import create_engine
import os
import xlsxwriter

# FunÃ§Ãµes que representam cada pÃ¡gina
def login_form():
Â  Â  """Exibe o formulÃ¡rio de login com um design aprimorado."""
Â  Â  
Â  Â  col1, col2, col3 = st.columns([1, 2, 1])
Â  Â  
Â  Â  with col2:
Â  Â  Â  Â  st.markdown("<h2 style='text-align: center; color: #004d99; font-family: \'Arial Black\', sans-serif;'>Lince Distribuidora</h2>", unsafe_allow_html=True)
Â  Â  Â  Â  st.markdown("---")
Â  Â  Â  Â  
Â  Â  Â  Â  with st.form("login_form", clear_on_submit=False):
Â  Â  Â  Â  Â  Â  st.markdown("Por favor, insira suas credenciais para continuar.")
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  username = st.text_input("UsuÃ¡rio", key="username_input", placeholder="Digite seu nome de usuÃ¡rio")
Â  Â  Â  Â  Â  Â  password = st.text_input("Senha", type="password", key="password_input", placeholder="Digite sua senha")
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  st.markdown("<br>", unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  submit_button = st.form_submit_button("Entrar", use_container_width=True)
Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  if submit_button:
Â  Â  Â  Â  Â  Â  if username in st.session_state.LOGIN_INFO and st.session_state.LOGIN_INFO[username] == password:
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state['is_logged_in'] = True
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state['username'] = username
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state['current_page'] = 'home'
Â  Â  Â  Â  Â  Â  Â  Â  st.success("Login realizado com sucesso! Redirecionando...")
Â  Â  Â  Â  Â  Â  Â  Â  st.balloons()
Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.error("UsuÃ¡rio ou senha incorretos.")

def main_page():
Â  Â  st.markdown(f"<h1 style='text-align: center;'>PÃ¡gina Inicial</h1>", unsafe_allow_html=True)
Â  Â  st.markdown(f"<h3 style='text-align: center;'>Bem-vindo(a), **{st.session_state['username']}**!</h3>", unsafe_allow_html=True)
Â  Â  st.markdown("---")

Â  Â  col1, col2 = st.columns(2)
Â  Â  with col1:
Â  Â  Â  Â  if st.button("LogÃ­stica", use_container_width=True):
Â  Â  Â  Â  Â  Â  st.session_state['current_page'] = 'logistics'
Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  with col2:
Â  Â  Â  Â  if st.button("Comercial", use_container_width=True):
Â  Â  Â  Â  Â  Â  st.session_state['current_page'] = 'commercial'
Â  Â  Â  Â  Â  Â  st.rerun()

Â  Â  col3, col4 = st.columns(2)
Â  Â  with col3:
Â  Â  Â  Â  if st.button("RH", use_container_width=True):
Â  Â  Â  Â  Â  Â  st.session_state['current_page'] = 'rh'
Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  # A opÃ§Ã£o "TI" foi removida daqui
Â  Â  with col4: # Este col4 agora corresponderÃ¡ ao botÃ£o SÃ­tio
Â  Â  Â  Â  if st.button("SÃ­tio", use_container_width=True):
Â  Â  Â  Â  Â  Â  st.session_state['current_page'] = 'site'
Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  
Â  Â  st.markdown("---")

Â  Â  if st.button("Sair", use_container_width=True):
Â  Â  Â  Â  st.session_state['is_logged_in'] = False
Â  Â  Â  Â  st.session_state.pop('username', None)
Â  Â  Â  Â  st.session_state.pop('current_page', None)
Â  Â  Â  Â  st.rerun()

# --- Novas funÃ§Ãµes para o banco de dados ---
def setup_database():
Â  Â  """Cria a conexÃ£o com o banco de dados SQLite."""
Â  Â  # O arquivo vasilhames.db serÃ¡ criado automaticamente
Â  Â  engine = create_engine('sqlite:///vasilhames.db')
Â  Â  return engine

def load_from_db(table_name, engine):
Â  Â  """Carrega todos os dados de uma tabela do banco de dados."""
Â  Â  if engine.dialect.has_table(engine.connect(), table_name):
Â  Â  Â  Â  return pd.read_sql_table(table_name, con=engine)
Â  Â  return pd.DataFrame()

def logistics_page():
Â  Â  st.title("Setor de LogÃ­stica")
Â  Â  st.markdown("Bem-vindo(a) ao setor de LogÃ­stica. Abaixo estÃ£o os scripts disponÃ­veis para anÃ¡lise.")
Â  Â  
Â  Â  script_choice = st.selectbox(
Â  Â  Â  Â  "Selecione um script para executar:",
Â  Â  Â  Â  ("Selecione...", "AcurÃ¡cia", "Validade", "Vasilhames", "Abastecimento")
Â  Â  )
Â  Â  
Â  Â  st.write("---")

Â  Â  if script_choice == "AcurÃ¡cia":
Â  Â  Â  Â  st.subheader("AcurÃ¡cia de Estoque")
Â  Â  Â  Â  st.markdown("Calcula a acurÃ¡cia diÃ¡ria e mensal do estoque a partir de um arquivo Excel.")
Â  Â  Â  Â  uploaded_file = st.file_uploader("Envie o arquivo 'Acuracia estoque.xlsx'", type=["xlsx"])
Â  Â  Â  Â  if uploaded_file is not None:
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  df = pd.read_excel(uploaded_file, header=[0, 1], sheet_name=0)
Â  Â  Â  Â  Â  Â  Â  Â  products_to_remove = ['185039 - Garrafa 0,30l', '471 - Garrafa 0,60l (3 )']
Â  Â  Â  Â  Â  Â  Â  Â  first_level_cols = [col[0] for col in df.columns]
Â  Â  Â  Â  Â  Â  Â  Â  second_level_cols = [col[1] for col in df.columns]
Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  prod_cod_col = [col for col in df.columns if col[1] == 'Prod CÃ³d'][0]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_data = df.set_index(prod_cod_col)
Â  Â  Â  Â  Â  Â  Â  Â  except IndexError:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_data = df.set_index(df.columns[0])
Â  Â  Â  Â  Â  Â  Â  Â  df_data = df_data[~df_data.index.isin(products_to_remove)].copy()
Â  Â  Â  Â  Â  Â  Â  Â  df_data = df_data[~df_data.index.astype(str).str.contains('Totais', na=False)].copy()
Â  Â  Â  Â  Â  Â  Â  Â  data_types = ['Saldo Final', 'Contagem', 'DiferenÃ§a', 'Acuracidade Estoque']
Â  Â  Â  Â  Â  Â  Â  Â  unique_dates = sorted(list(set([col for col in first_level_cols if col not in ['Data', 'Prod CÃ³d']])))
Â  Â  Â  Â  Â  Â  Â  Â  new_rows = []
Â  Â  Â  Â  Â  Â  Â  Â  for product in df_data.index:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for date in unique_dates:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row_data = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Prod CÃ³d': product,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Dia': date,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for data_type in data_types:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  col_name = (date, data_type)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  value = df_data.loc[product, col_name]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if isinstance(value, str) and value == '-':
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  value = 0
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row_data[data_type] = pd.to_numeric(value, errors='coerce')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except KeyError:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row_data[data_type] = np.nan
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  new_rows.append(row_data)
Â  Â  Â  Â  Â  Â  Â  Â  df_final = pd.DataFrame(new_rows)
Â  Â  Â  Â  Â  Â  Â  Â  df_final['Saldo Final'] = df_final['Saldo Final'].apply(lambda x: max(0, x))
Â  Â  Â  Â  Â  Â  Â  Â  df_final['DiferenÃ§a'] = df_final['DiferenÃ§a'].abs()
Â  Â  Â  Â  Â  Â  Â  Â  daily_accuracy = df_final.groupby('Dia').apply(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  lambda x: (x['Saldo Final'].sum() - x['DiferenÃ§a'].sum()) / x['Saldo Final'].sum() if x['Saldo Final'].sum() != 0 else 0
Â  Â  Â  Â  Â  Â  Â  Â  ).reset_index(name='AcurÃ¡cia DiÃ¡ria')
Â  Â  Â  Â  Â  Â  Â  Â  total_saldo_final_mes = df_final['Saldo Final'].sum()
Â  Â  Â  Â  Â  Â  Â  Â  total_diferenca_mes = df_final['DiferenÃ§a'].sum()
Â  Â  Â  Â  Â  Â  Â  Â  monthly_accuracy = (total_saldo_final_mes - total_diferenca_mes) / total_saldo_final_mes if total_saldo_final_mes != 0 else 0
Â  Â  Â  Â  Â  Â  Â  Â  df_final = pd.merge(df_final, daily_accuracy, on='Dia', how='left')
Â  Â  Â  Â  Â  Â  Â  Â  df_final['AcurÃ¡cia Mensal'] = monthly_accuracy
Â  Â  Â  Â  Â  Â  Â  Â  df_final = df_final.sort_values(by=['Dia', 'Prod CÃ³d'])
Â  Â  Â  Â  Â  Â  Â  Â  df_final['Dia'] = pd.to_datetime(df_final['Dia']).dt.strftime('%Y-%m-%d')
Â  Â  Â  Â  Â  Â  Â  Â  numeric_cols = ['Saldo Final', 'Contagem', 'DiferenÃ§a', 'Acuracidade Estoque']
Â  Â  Â  Â  Â  Â  Â  Â  df_final[numeric_cols] = df_final[numeric_cols].round(2)
Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("ğŸ“Š Resultado da AcurÃ¡cia")
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(df_final)
Â  Â  Â  Â  Â  Â  Â  Â  excel_data = io.BytesIO()
Â  Â  Â  Â  Â  Â  Â  Â  df_final.to_excel(excel_data, index=False, engine='xlsxwriter')
Â  Â  Â  Â  Â  Â  Â  Â  excel_data.seek(0)
Â  Â  Â  Â  Â  Â  Â  Â  st.download_button(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label="ğŸ“¥ Baixar Arquivo Processado",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data=excel_data,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_name='Acuracia_estoque_processado.xlsx',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Ocorreu um erro no script de AcurÃ¡cia: {e}")

Â  Â  elif script_choice == "Validade":
Â  Â  Â  Â  st.subheader("Controle de Validade")
Â  Â  Â  Â  st.markdown("Consolida dados de validade de um arquivo Excel e um arquivo de texto, e gera um relatÃ³rio com status de validade e contagens.")
Â  Â  Â  Â  def parse_estoque_txt(file_content):
Â  Â  Â  Â  Â  Â  lines = [line.decode('latin1') for line in file_content.getvalue().splitlines()]
Â  Â  Â  Â  Â  Â  separator_string = '-' * 116
Â  Â  Â  Â  Â  Â  separator_indices = [i for i, line in enumerate(lines) if separator_string in line]
Â  Â  Â  Â  Â  Â  if len(separator_indices) < 2:
Â  Â  Â  Â  Â  Â  Â  Â  st.warning("NÃ£o foi possÃ­vel localizar os separadores de colunas no arquivo TXT.")
Â  Â  Â  Â  Â  Â  Â  Â  return pd.DataFrame()
Â  Â  Â  Â  Â  Â  start_line = separator_indices[1] + 1
Â  Â  Â  Â  Â  Â  col_names = ['COD.RED.', 'DESCRIÃ‡ÃƒO', 'SLD INICIAL CX', 'SLD INICIAL UN', 'ENTRADAS CX', 'ENTRADAS UN', 'SAÃDAS CX', 'SAÃDAS UN', 'SALDO FÃSICO CX', 'SALDO FÃSICO UN', 'CONT. FÃSICA CX', 'CONT. FÃSICA UN', 'DIFERENÃ‡A CX', 'DIFERENÃ‡A UN']
Â  Â  Â  Â  Â  Â  data = []
Â  Â  Â  Â  Â  Â  pattern = re.compile(r'^\s*(\d+)\s+(.+?)\s*(\d*)\s*(\d*)\s*I\s*(\d*)\s*(\d*)\s*I\s*(\d*)\s*(\d*)\s*I\s*(\d*)\s*(\d*)\s*I\s*(\d*)\s*(\d*)\s*I\s*(\d*)\s*(\d*)\s*I')
Â  Â  Â  Â  Â  Â  for line in lines[start_line:]:
Â  Â  Â  Â  Â  Â  Â  Â  line = line.strip()
Â  Â  Â  Â  Â  Â  Â  Â  if not line:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  Â  Â  match = pattern.match(line)
Â  Â  Â  Â  Â  Â  Â  Â  if match:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  groups = match.groups()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row_values = [groups[0], groups[1]]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for i in range(2, len(groups), 2):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cx = groups[i].strip()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  un = groups[i+1].strip()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row_values.extend([int(cx) if cx else 0, int(un) if un else 0])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if len(row_values) == 14:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data.append(row_values)
Â  Â  Â  Â  Â  Â  df_txt_raw = pd.DataFrame(data, columns=col_names)
Â  Â  Â  Â  Â  Â  return df_txt_raw
Â  Â  Â  Â  uploaded_excel_file = st.file_uploader("Envie o arquivo Excel 'Controle de Validade.xlsx'", type=["xlsx"])
Â  Â  Â  Â  uploaded_txt_file = st.file_uploader("Envie o arquivo de texto de estoque", type=["txt"])
Â  Â  Â  Â  if uploaded_excel_file is not None and uploaded_txt_file is not None:
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  df_validade = pd.read_excel(uploaded_excel_file)
Â  Â  Â  Â  Â  Â  Â  Â  df_validade.columns = df_validade.columns.str.replace(r'\s+', ' ', regex=True).str.strip()
Â  Â  Â  Â  Â  Â  Â  Â  df_estoque = parse_estoque_txt(uploaded_txt_file)
Â  Â  Â  Â  Â  Â  Â  Â  if df_estoque.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("O arquivo TXT estÃ¡ vazio ou nÃ£o pÃ´de ser processado.")
Â  Â  Â  Â  Â  Â  Â  Â  validity_cols = ['Validade', 'Validade.1', 'Validade.2', 'Validade.3', 'Validade.4']
Â  Â  Â  Â  Â  Â  Â  Â  quantity_caixa_cols = ['Quantidade (CAIXA)', 'Quantidade 2 (CAIXA)', 'Quantidade 3 (CAIXA)', 'Quantidade 4 (CAIXA)', 'Quantidade 5 (CAIXA)']
Â  Â  Â  Â  Â  Â  Â  Â  quantity_unidade_cols = ['Quantidade (UNIDADE)', 'Quantidade 2 (UNIDADE)', 'Quantidade 3 (UNIDADE)', 'Quantidade 4 (UNIDADE)', 'Quantidade 5 (UNIDADE)']
Â  Â  Â  Â  Â  Â  Â  Â  all_validity_entries = []
Â  Â  Â  Â  Â  Â  Â  Â  for i in range(len(validity_cols)):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cols_to_check = ['Qual Produto ?', validity_cols[i], quantity_caixa_cols[i], quantity_unidade_cols[i]]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if all(col in df_validade.columns for col in cols_to_check):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  temp_df = df_validade[['Qual Produto ?', validity_cols[i], quantity_caixa_cols[i], quantity_unidade_cols[i]]].copy()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  temp_df.rename(columns={validity_cols[i]: 'Validade', quantity_caixa_cols[i]: 'Quantidade (CAIXA)', quantity_unidade_cols[i]: 'Quantidade (UNIDADE)'}, inplace=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_validity_entries.append(temp_df)
Â  Â  Â  Â  Â  Â  Â  Â  all_validity_entries = [df for df in all_validity_entries if not df.dropna(subset=['Validade']).empty]
Â  Â  Â  Â  Â  Â  Â  Â  if all_validity_entries:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  melted_df_validade_all = pd.concat(all_validity_entries, ignore_index=True)
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  melted_df_validade_all = pd.DataFrame(columns=['Qual Produto ?', 'Validade', 'Quantidade (CAIXA)', 'Quantidade (UNIDADE)'])
Â  Â  Â  Â  Â  Â  Â  Â  melted_df_validade_all.dropna(subset=['Validade'], inplace=True)
Â  Â  Â  Â  Â  Â  Â  Â  melted_df_validade_all['Validade'] = pd.to_datetime(melted_df_validade_all['Validade'], errors='coerce')
Â  Â  Â  Â  Â  Â  Â  Â  melted_df_validade_all.dropna(subset=['Validade'], inplace=True)
Â  Â  Â  Â  Â  Â  Â  Â  melted_df_validade_all['Quantidade (CAIXA)'] = pd.to_numeric(melted_df_validade_all['Quantidade (CAIXA)'], errors='coerce').fillna(0)
Â  Â  Â  Â  Â  Â  Â  Â  melted_df_validade_all['Quantidade (UNIDADE)'] = pd.to_numeric(melted_df_validade_all['Quantidade (UNIDADE)'], errors='coerce').fillna(0)
Â  Â  Â  Â  Â  Â  Â  Â  split_data_validade = melted_df_validade_all['Qual Produto ?'].astype(str).str.split(' - ', n=1, expand=True)
Â  Â  Â  Â  Â  Â  Â  Â  melted_df_validade_all['Codigo Produto'] = split_data_validade[0].str.strip()
Â  Â  Â  Â  Â  Â  Â  Â  melted_df_validade_all['Nome Produto'] = split_data_validade[1].str.strip()
Â  Â  Â  Â  Â  Â  Â  Â  def extract_units_per_box(product_name):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  product_name = str(product_name).upper().replace(' ', '')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  match_multiplication = re.search(r'(\d+)X(\d+)(?:UN|U)', product_name)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if match_multiplication:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  factor1 = int(match_multiplication.group(1))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  factor2 = int(match_multiplication.group(2))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return factor1 * factor2
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  match_direct = re.search(r'(\d+)(?:UN|U)', product_name)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if match_direct:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return int(match_direct.group(1))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return 1
Â  Â  Â  Â  Â  Â  Â  Â  melted_df_validade_all['Units_Per_Box_Temp'] = melted_df_validade_all['Nome Produto'].apply(extract_units_per_box)
Â  Â  Â  Â  Â  Â  Â  Â  grouped = melted_df_validade_all.groupby(['Codigo Produto', 'Nome Produto', 'Validade']).agg({'Quantidade (CAIXA)': 'sum', 'Quantidade (UNIDADE)': 'sum', 'Units_Per_Box_Temp': 'first'}).reset_index()
Â  Â  Â  Â  Â  Â  Â  Â  def convert_total_units_to_boxes_and_units(row):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  units_per_box = row['Units_Per_Box_Temp'] or 1
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  total_units = (row['Quantidade (CAIXA)'] * units_per_box) + row['Quantidade (UNIDADE)']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row['Quantidade (CAIXA)'] = total_units // units_per_box
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row['Quantidade (UNIDADE)'] = total_units % units_per_box
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return row
Â  Â  Â  Â  Â  Â  Â  Â  grouped = grouped.apply(convert_total_units_to_boxes_and_units, axis=1)
Â  Â  Â  Â  Â  Â  Â  Â  grouped.drop('Units_Per_Box_Temp', axis=1, inplace=True)
Â  Â  Â  Â  Â  Â  Â  Â  data_atual = datetime.now()
Â  Â  Â  Â  Â  Â  Â  Â  grouped['Dias para Vencer'] = (grouped['Validade'] - data_atual).dt.days
Â  Â  Â  Â  Â  Â  Â  Â  conditions = [grouped['Dias para Vencer'] <= 45, (grouped['Dias para Vencer'] > 45) & (grouped['Dias para Vencer'] <= 60), grouped['Dias para Vencer'] > 60]
Â  Â  Â  Â  Â  Â  Â  Â  choices = ['VALIDADE CURTA', 'ATENÃ‡ÃƒO', 'OK']
Â  Â  Â  Â  Â  Â  Â  Â  grouped['Status Validade'] = np.select(conditions, choices, default='Indefinido')
Â  Â  Â  Â  Â  Â  Â  Â  grouped['Validade_DateOnly'] = grouped['Validade'].dt.date
Â  Â  Â  Â  Â  Â  Â  Â  sorted_grouped = grouped.sort_values(by=['Codigo Produto', 'Validade']).reset_index(drop=True)
Â  Â  Â  Â  Â  Â  Â  Â  sorted_grouped['Validade_Rank'] = sorted_grouped.groupby('Codigo Produto')['Validade'].rank(method='first').astype(int)
Â  Â  Â  Â  Â  Â  Â  Â  final_rows = []
Â  Â  Â  Â  Â  Â  Â  Â  for product_code, group in sorted_grouped.groupby('Codigo Produto'):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row = {'Codigo Produto': product_code, 'Nome Produto': group['Nome Produto'].iloc[0]}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for _, r in group.iterrows():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  i = r['Validade_Rank']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row[f'Validade {i}'] = r['Validade_DateOnly']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row[f'Quantidade (CAIXA) {i}'] = r['Quantidade (CAIXA)']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row[f'Quantidade (UNIDADE) {i}'] = r['Quantidade (UNIDADE)']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row[f'Dias para Vencer {i}'] = r['Dias para Vencer']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  row[f'Status Validade {i}'] = r['Status Validade']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final_rows.append(row)
Â  Â  Â  Â  Â  Â  Â  Â  final_df = pd.DataFrame(final_rows)
Â  Â  Â  Â  Â  Â  Â  Â  if not df_estoque.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_saldo = df_estoque[['COD.RED.', 'SALDO FÃSICO CX', 'SALDO FÃSICO UN']].drop_duplicates('COD.RED.')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_saldo.rename(columns={'SALDO FÃSICO CX': 'Saldo FÃ­sico TXT Caixa', 'SALDO FÃSICO UN': 'Saldo FÃ­sico TXT Unidade'}, inplace=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final_df = pd.merge(final_df, df_saldo, how='left', left_on='Codigo Produto', right_on='COD.RED.')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final_df.drop('COD.RED.', axis=1, inplace=True)
Â  Â  Â  Â  Â  Â  Â  Â  quantidade_caixa_cols = [col for col in final_df.columns if re.match(r'Quantidade \(CAIXA\) \d+', col)]
Â  Â  Â  Â  Â  Â  Â  Â  quantidade_unidade_cols = [col for col in final_df.columns if re.match(r'Quantidade \(UNIDADE\) \d+', col)]
Â  Â  Â  Â  Â  Â  Â  Â  final_df['Contagem Fisica CX'] = final_df[quantidade_caixa_cols].sum(axis=1)
Â  Â  Â  Â  Â  Â  Â  Â  final_df['Contagem Fisica UN'] = final_df[quantidade_unidade_cols].sum(axis=1)
Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("âœ… RelatÃ³rio de Validade Gerado")
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(final_df)
Â  Â  Â  Â  Â  Â  Â  Â  excel_data = io.BytesIO()
Â  Â  Â  Â  Â  Â  Â  Â  final_df.to_excel(excel_data, sheet_name='Controle de Estoque', index=False)
Â  Â  Â  Â  Â  Â  Â  Â  excel_data.seek(0)
Â  Â  Â  Â  Â  Â  Â  Â  st.download_button(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label="ğŸ“¥ Baixar RelatÃ³rio de Validade",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data=excel_data,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_name="Controle_Estoque_Completo.xlsx",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Ocorreu um erro ao processar os arquivos: {e}")

Â  Â  elif script_choice == "Vasilhames":
Â  Â  Â  Â  st.subheader("Controle de Vasilhames")
Â  Â  Â  Â  st.markdown("Este script consolida dados de vasilhames de diferentes fontes (Excel, TXT, PDF) e gera um relatÃ³rio unificado.")
Â  Â  Â  Â  
Â  Â  Â  Â  # Cria a conexÃ£o com o banco de dados
Â  Â  Â  Â  engine = setup_database()

Â  Â  Â  Â  def process_txt_file_st(file_content):
Â  Â  Â  Â  Â  Â  content = file_content.getvalue().decode('latin1')
Â  Â  Â  Â  Â  Â  filename_date_match = re.search(r'ESTOQUE(\d{4})\.TXT', file_content.name)
Â  Â  Â  Â  Â  Â  if filename_date_match:
Â  Â  Â  Â  Â  Â  Â  Â  day = filename_date_match.group(1)[:2]
Â  Â  Â  Â  Â  Â  Â  Â  month = filename_date_match.group(1)[2:]
Â  Â  Â  Â  Â  Â  Â  Â  year = datetime.now().year
Â  Â  Â  Â  Â  Â  Â  Â  effective_date_str = datetime.strptime(f"{day}/{month}/{year}", '%d/%m/%Y').strftime('%d/%m')
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.error("Nome do arquivo TXT invÃ¡lido. O formato deve ser 'ESTOQUEDDMM.TXT'.")
Â  Â  Â  Â  Â  Â  Â  Â  return None, None
Â  Â  Â  Â  Â  Â  product_code_to_vasilhame_map = {'563-008': '563-008 - BARRIL INOX 30L', '564-009': '564-009 - BARRIL INOX 50L', '591-002': '591-002 - CAIXA PLASTICA HEINEKEN 330ML', '587-002': '587-002 - CAIXA PLASTICA HEINEKEN 600ML', '550-001': '550-001 - CAIXA PLASTICA 600ML', '555-001': '555-001 - CAIXA PLASTICA 1L', '546-004': '546-004 - CAIXA PLASTICA 24UN 300ML', '565-002': '565-002 - CILINDRO CO2', '550-012': '550-001 - CAIXA PLASTICA 600ML', '803-039': '550-001 - CAIXA PLASTICA 600ML', '803-037': '550-001 - CAIXA PLASTICA 600ML'}
Â  Â  Â  Â  Â  Â  parsed_data = []
Â  Â  Â  Â  Â  Â  pattern = re.compile(r'^\s*"?(\d{3}-\d{3})[^"\n]*?"?.*?"?([\d.]+)"?\s*$', re.MULTILINE)
Â  Â  Â  Â  Â  Â  for line in content.splitlines():
Â  Â  Â  Â  Â  Â  Â  Â  match = pattern.match(line)
Â  Â  Â  Â  Â  Â  Â  Â  if match:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  product_code = match.group(1).strip()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  quantity = match.group(2).replace('.', '').strip()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if product_code in product_code_to_vasilhame_map:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  parsed_data.append({'PRODUTO_CODE': product_code, 'QUANTIDADE': int(quantity) if quantity.isdigit() else 0})
Â  Â  Â  Â  Â  Â  if not parsed_data:
Â  Â  Â  Â  Â  Â  Â  Â  return None, effective_date_str
Â  Â  Â  Â  Â  Â  df_estoque = pd.DataFrame(parsed_data)
Â  Â  Â  Â  Â  Â  df_estoque['Vasilhame'] = df_estoque['PRODUTO_CODE'].map(product_code_to_vasilhame_map)
Â  Â  Â  Â  Â  Â  df_txt_qty = df_estoque.groupby('Vasilhame')['QUANTIDADE'].sum().reset_index()
Â  Â  Â  Â  Â  Â  df_txt_qty.rename(columns={'QUANTIDADE': 'Qtd. emprestimo'}, inplace=True)
Â  Â  Â  Â  Â  Â  return df_txt_qty, effective_date_str

Â  Â  Â  Â  def process_pdf_content(pdf_file, product_map):
Â  Â  Â  Â  Â  Â  parsed_data = []
Â  Â  Â  Â  Â  Â  filename_match = re.search(r'([a-zA-Z\s]+)\s+(\d{2}-\d{2}-\d{4})\.pdf', pdf_file.name)
Â  Â  Â  Â  Â  Â  if not filename_match:
Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Erro: Nome de arquivo PDF invÃ¡lido: {pdf_file.name}. Formato esperado: 'PDV DD-MM-YYYY.pdf'")
Â  Â  Â  Â  Â  Â  Â  Â  return pd.DataFrame()
Â  Â  Â  Â  Â  Â  source_name = filename_match.group(1).strip()
Â  Â  Â  Â  Â  Â  date_str = filename_match.group(2)
Â  Â  Â  Â  Â  Â  effective_date_str = datetime.strptime(date_str, '%d-%m-%Y').strftime('%d/%m')
Â  Â  Â  Â  Â  Â  source_to_col_map = {'PONTA GROSSA': 'Ponta Grossa (0328)', 'ARARAQUARA': 'Araraquara (0336)', 'ITU': 'Itu (0002)'}
Â  Â  Â  Â  Â  Â  col_suffix = source_to_col_map.get(source_name.upper(), source_name)
Â  Â  Â  Â  Â  Â  pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.getvalue()))
Â  Â  Â  Â  Â  Â  pdf_content = ""
Â  Â  Â  Â  Â  Â  for page in pdf_reader.pages:
Â  Â  Â  Â  Â  Â  Â  Â  pdf_content += page.extract_text()
Â  Â  Â  Â  Â  Â  data_line_pattern = re.compile(r'^\s*"?(\d{15,})[^"\n]*?"?.*?"?([-+]?[\d.,]+)"?\s*$', re.MULTILINE)
Â  Â  Â  Â  Â  Â  for line_match in data_line_pattern.finditer(pdf_content):
Â  Â  Â  Â  Â  Â  Â  Â  material_code = line_match.group(1).strip()
Â  Â  Â  Â  Â  Â  Â  Â  saldo_str = line_match.group(2).replace('.', '').replace(',', '.').strip()
Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  saldo = float(saldo_str)
Â  Â  Â  Â  Â  Â  Â  Â  except ValueError:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  saldo = 0.0
Â  Â  Â  Â  Â  Â  Â  Â  if material_code in product_map:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  vasilhame = product_map[material_code]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  credito = abs(saldo) if saldo < 0 else 0.0
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  debito = saldo if saldo >= 0 else 0.0
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  parsed_data.append({'Vasilhame': vasilhame, 'Dia': effective_date_str, f'Credito {col_suffix}': credito, f'Debito {col_suffix}': debito})
Â  Â  Â  Â  Â  Â  if not parsed_data:
Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"Nenhum dado de PDV encontrado no arquivo: {pdf_file.name}")
Â  Â  Â  Â  Â  Â  Â  Â  return pd.DataFrame()
Â  Â  Â  Â  Â  Â  return pd.DataFrame(parsed_data).groupby(['Vasilhame', 'Dia'], as_index=False).sum()
Â  Â  Â  Â  
Â  Â  Â  Â  uploaded_txt_files = st.file_uploader("Envie os arquivos TXT de emprÃ©stimos (Ex: ESTOQUE0102.TXT)", type=["txt"], accept_multiple_files=True)
Â  Â  Â  Â  uploaded_excel_contagem = st.file_uploader("Envie o arquivo Excel de contagem (Ex: Contagem Vasilhames.xlsx)", type=["xlsx"])
Â  Â  Â  Â  uploaded_pdf_files = st.file_uploader("Envie os arquivos PDF de fÃ¡brica", type=["pdf"], accept_multiple_files=True)
Â  Â  Â  Â  
Â  Â  Â  Â  if st.button("Processar e Consolidar Dados"):
Â  Â  Â  Â  Â  Â  if uploaded_txt_files and uploaded_excel_contagem is not None:
Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info("Processando e salvando novos dados. Por favor, aguarde...")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # --- Processamento e Salvamento dos novos arquivos ---
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  new_txt_data = []
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for uploaded_txt_file in uploaded_txt_files:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_txt_qty, effective_date_str = process_txt_file_st(uploaded_txt_file)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if df_txt_qty is not None:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_txt_qty['Dia'] = effective_date_str
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  new_txt_data.append(df_txt_qty)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if new_txt_data:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_new_txt = pd.concat(new_txt_data, ignore_index=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_new_txt.to_sql('txt_data', con=engine, if_exists='append', index=False)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("Novos dados TXT salvos no banco de dados!")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("Nenhum dado TXT para salvar.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  new_pdf_data = []
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if uploaded_pdf_files:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pdf_material_code_to_vasilhame_map = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  '000000000000215442': '587-002 - CAIXA PLASTICA HEINEKEN 600ML', '000000000000215208': '587-002 - CAIXA PLASTICA HEINEKEN 600ML', '000000000000381411': '591-002 - CAIXA PLASTICA HEINEKEN 330ML', '000000000000107380': '555-001 - CAIXA PLASTICA 1L', '000000000000152598': '546-004 - CAIXA PLASTICA 24UN 300ML', '000000000000000470': '550-001 - CAIXA PLASTICA 600ML'
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for pdf_file in uploaded_pdf_files:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_pdf_current = process_pdf_content(pdf_file, pdf_material_code_to_vasilhame_map)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not df_pdf_current.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  new_pdf_data.append(df_pdf_current)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if new_pdf_data:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_new_pdf = pd.concat(new_pdf_data, ignore_index=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_new_pdf.to_sql('pdf_data', con=engine, if_exists='append', index=False)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("Novos dados PDF salvos no banco de dados!")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("Nenhum dado PDF para salvar.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # --- Carregamento dos dados histÃ³ricos (do banco) ---
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_all_processed_txt_data = load_from_db('txt_data', engine)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_all_processed_pdf_data = load_from_db('pdf_data', engine)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if df_all_processed_txt_data.empty and df_all_processed_pdf_data.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("Nenhum dado TXT ou PDF encontrado no banco de dados.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # --- O restante do seu cÃ³digo de consolidaÃ§Ã£o ---
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_contagem = pd.read_excel(uploaded_excel_contagem, sheet_name='Respostas ao formulÃ¡rio 1')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_contagem['Carimbo de data/hora'] = pd.to_datetime(df_contagem['Carimbo de data/hora'])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_historical_excel = df_contagem.copy()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_historical_excel['Dia'] = df_historical_excel['Carimbo de data/hora'].dt.strftime('%d/%m')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_excel_daily_counts = df_historical_excel.groupby(['Qual vasilhame ?', 'Dia'])['Total'].sum().reset_index()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_excel_daily_counts.rename(columns={'Qual vasilhame ?': 'Vasilhame', 'Total': 'Contagem'}, inplace=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_master_combinations = pd.concat([
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_excel_daily_counts[['Vasilhame', 'Dia']],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_all_processed_txt_data[['Vasilhame', 'Dia']] if 'Vasilhame' in df_all_processed_txt_data.columns else pd.DataFrame(columns=['Vasilhame', 'Dia']),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_all_processed_pdf_data[['Vasilhame', 'Dia']] if 'Vasilhame' in df_all_processed_pdf_data.columns else pd.DataFrame(columns=['Vasilhame', 'Dia'])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]).drop_duplicates().reset_index(drop=True)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_final = pd.merge(df_master_combinations, df_excel_daily_counts, on=['Vasilhame', 'Dia'], how='left')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_final = pd.merge(df_final, df_all_processed_txt_data, on=['Vasilhame', 'Dia'], how='left')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_final = pd.merge(df_final, df_all_processed_pdf_data, on=['Vasilhame', 'Dia'], how='left')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_final['Contagem'] = pd.to_numeric(df_final['Contagem'], errors='coerce').fillna(0)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_final['Qtd. emprestimo'] = pd.to_numeric(df_final['Qtd. emprestimo'], errors='coerce').fillna(0)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_final['Total Revenda'] = df_final['Qtd. emprestimo'] + df_final['Contagem'] + df_final.filter(like='Credito').sum(axis=1) - df_final.filter(like='Debito').sum(axis=1)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_final['DiferenÃ§a'] = df_final.groupby('Vasilhame')['Total Revenda'].diff()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("âœ… Tabela Consolidada de Vasilhames")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(df_final)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  output = io.BytesIO()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_final.to_excel(output, index=False)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  output.seek(0)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.download_button(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label="ğŸ“¥ Baixar Tabela Consolidada",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data=output,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_name="Vasilhames_Consolidado.xlsx",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Ocorreu um erro durante o processamento: {e}")
Â  Â  
Â  Â  elif script_choice == "Abastecimento":
Â  Â  Â  Â  st.subheader("AnÃ¡lise de Abastecimento")
Â  Â  Â  Â  st.markdown("Este script processa dados de abastecimento e gera relatÃ³rios separados para Diesel e Arla, com mÃ©dias de consumo por KM.")
Â  Â  Â  Â  
Â  Â  Â  Â  uploaded_file = st.file_uploader("Envie o arquivo de abastecimento (.xlsx ou .csv)", type=["xlsx", "csv"])
Â  Â  Â  Â  
Â  Â  Â  Â  if uploaded_file is not None:
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  st.info("Processando arquivo de abastecimento. Isso pode levar alguns segundos...")
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  # Nova lÃ³gica de leitura baseada na extensÃ£o do arquivo
Â  Â  Â  Â  Â  Â  Â  Â  file_extension = os.path.splitext(uploaded_file.name)[1].lower()

Â  Â  Â  Â  Â  Â  Â  Â  if file_extension == '.xlsx':
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df = pd.read_excel(uploaded_file, engine='openpyxl')
Â  Â  Â  Â  Â  Â  Â  Â  elif file_extension == '.csv':
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df = pd.read_csv(uploaded_file)
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error("Formato de arquivo nÃ£o suportado. Por favor, envie um arquivo .xlsx ou .csv.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  # NormalizaÃ§Ã£o de colunas
Â  Â  Â  Â  Â  Â  Â  Â  df.columns = [col.upper().strip().replace('HORA', 'HORÃRIO') for col in df.columns]
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  # Garante que as colunas de data e hora estÃ£o no formato correto
Â  Â  Â  Â  Â  Â  Â  Â  if 'DATA ABASTECIMENTO' not in df.columns and 'DATA' in df.columns:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df['DATA ABASTECIMENTO'] = pd.to_datetime(df['DATA'], errors='coerce')
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df['DATA ABASTECIMENTO'] = pd.to_datetime(df['DATA ABASTECIMENTO'], errors='coerce')
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  if 'HORÃRIO' in df.columns:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df['HORÃRIO'] = pd.to_datetime(df['HORÃRIO'], format='%H:%M:%S', errors='coerce').dt.time
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  if 'MOTORISTA' not in df.columns and 'RESPONSÃVEL' in df.columns:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df['MOTORISTA'] = df['RESPONSÃVEL']

Â  Â  Â  Â  Â  Â  Â  Â  df['KM'] = pd.to_numeric(df['KM'], errors='coerce')
Â  Â  Â  Â  Â  Â  Â  Â  df['LITROS'] = pd.to_numeric(df['LITROS'], errors='coerce')

Â  Â  Â  Â  Â  Â  Â  Â  # Define as colunas de saÃ­da
Â  Â  Â  Â  Â  Â  Â  Â  colunas_saida = [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'DATA ABASTECIMENTO', 'HORÃRIO', 'TIPO DE ABASTECIMENTO', 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'PLACA', 'KM', 'ALERTA KM', 'MOTORISTA', 'LITROS', 'MÃ©dia de litros por KM'
Â  Â  Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  df_diesel = df[df['TIPO DE ABASTECIMENTO'] == 'DIESEL'].copy()
Â  Â  Â  Â  Â  Â  Â  Â  if not df_diesel.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  excel_data_diesel = io.BytesIO()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with pd.ExcelWriter(excel_data_diesel, engine='xlsxwriter') as writer:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  placas_diesel = sorted(df_diesel['PLACA'].unique())
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for placa in placas_diesel:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa = df_diesel[df_diesel['PLACA'] == placa].copy()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa.sort_values(by=['DATA ABASTECIMENTO', 'HORÃRIO'], ascending=True, inplace=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa['DISTANCIA_PERCORRIDA'] = df_placa['KM'].diff()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa['MEDIA_LITROS_KM'] = df_placa['LITROS'] / df_placa['DISTANCIA_PERCORRIDA']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa['ALERTA KM'] = ''
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa.loc[df_placa['DISTANCIA_PERCORRIDA'] < 0, 'ALERTA KM'] = 'ALERTA: KM menor que o registro anterior!'

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa['MÃ©dia de litros por KM'] = df_placa['MEDIA_LITROS_KM'].mean()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa.loc[df_placa.index[:-1], 'MÃ©dia de litros por KM'] = ''
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa_output = df_placa.rename(columns={'DATA ABASTECIMENTO': 'Data Abastecimento', 'TIPO DE ABASTECIMENTO': 'Tipo de Abastecimento'})
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa_output[colunas_saida].to_excel(writer, sheet_name=placa, index=False)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  excel_data_diesel.seek(0)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("Planilha de Diesel processada com sucesso!")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.download_button(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label="ğŸ“¥ Baixar Planilha de Diesel",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data=excel_data_diesel,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_name="planilha_diesel.xlsx",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("NÃ£o foram encontrados dados de 'DIESEL' no arquivo.")
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  df_arla = df[df['TIPO DE ABASTECIMENTO'] == 'ARLA'].copy()
Â  Â  Â  Â  Â  Â  Â  Â  if not df_arla.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  excel_data_arla = io.BytesIO()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with pd.ExcelWriter(excel_data_arla, engine='xlsxwriter') as writer:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  placas_arla = sorted(df_arla['PLACA'].unique())
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for placa in placas_arla:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa = df_arla[df_arla['PLACA'] == placa].copy()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa.sort_values(by=['DATA ABASTECIMENTO', 'HORÃRIO'], ascending=True, inplace=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa['DISTANCIA_PERCORRIDA'] = df_placa['KM'].diff()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa['MEDIA_LITROS_KM'] = df_placa['LITROS'] / df_placa['DISTANCIA_PERCORRIDA']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa['ALERTA KM'] = ''
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa.loc[df_placa['DISTANCIA_PERCORRIDA'] < 0, 'ALERTA KM'] = 'ALERTA: KM menor que o registro anterior!'
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa['MÃ©dia de litros por KM'] = df_placa['MEDIA_LITROS_KM'].mean()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa.loc[df_placa.index[:-1], 'MÃ©dia de litros por KM'] = ''
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa_output = df_placa.rename(columns={'DATA ABASTECIMENTO': 'Data Abastecimento', 'TIPO DE ABASTECIMENTO': 'Tipo de Abastecimento'})
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_placa_output[colunas_saida].to_excel(writer, sheet_name=placa, index=False)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  excel_data_arla.seek(0)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success("Planilha de Arla processada com sucesso!")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.download_button(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label="ğŸ“¥ Baixar Planilha de Arla",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data=excel_data_arla,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_name="planilha_arla.xlsx",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("NÃ£o foram encontrados dados de 'ARLA' no arquivo.")

Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Ocorreu um erro ao processar o arquivo: {e}")

Â  Â  if st.button("Voltar para o InÃ­cio"):
Â  Â  Â  Â  st.session_state['current_page'] = 'home'
Â  Â  Â  Â  st.rerun()

def commercial_page():
Â  Â  st.title("Setor Comercial")
Â  Â  st.markdown("Bem-vindo(a) ao setor Comercial. Abaixo estÃ£o os scripts disponÃ­veis para anÃ¡lise.")

Â  Â  script_selection = st.selectbox(
Â  Â  Â  Â  "Selecione o script que deseja executar:",
Â  Â  Â  Â  ("Selecione...", "Troca de Canal", "Circuito ExecuÃ§Ã£o")
Â  Â  )

Â  Â  if script_selection == "Troca de Canal":
Â  Â  Â  Â  st.write("---")
Â  Â  Â  Â  st.subheader("Troca de Canal")
Â  Â  Â  Â  st.markdown("Este script transforma e consolida dados de planilhas de Google Forms, adicionando uma coluna de status com lista suspensa.")

Â  Â  Â  Â  def normalize_columns(columns_list):
Â  Â  Â  Â  Â  Â  """Normaliza uma lista de nomes de colunas."""
Â  Â  Â  Â  Â  Â  normalized_list = []
Â  Â  Â  Â  Â  Â  for col in columns_list:
Â  Â  Â  Â  Â  Â  Â  Â  col = re.sub(r'\s+', ' ', col).strip()
Â  Â  Â  Â  Â  Â  Â  Â  col = col.replace('\n', ' ')
Â  Â  Â  Â  Â  Â  Â  Â  normalized_list.append(col)
Â  Â  Â  Â  Â  Â  return normalized_list

Â  Â  Â  Â  def transform_google_forms_data(df):
Â  Â  Â  Â  Â  Â  """
Â  Â  Â  Â  Â  Â  Transforma dados de Google Forms, consolidando informaÃ§Ãµes e adicionando
Â  Â  Â  Â  Â  Â  uma coluna 'Status' com validaÃ§Ã£o de dados.
Â  Â  Â  Â  Â  Â  """
Â  Â  Â  Â  Â  Â  processed_records = []
Â  Â  Â  Â  Â  Â  for index, row in df.iterrows():
Â  Â  Â  Â  Â  Â  Â  Â  data_value = row.iloc[0] if len(row) > 0 else None
Â  Â  Â  Â  Â  Â  Â  Â  sv_value = row.iloc[1] if len(row) > 1 else None
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  vd_consolidated_parts = [str(row.iloc[col_idx]).strip() for col_idx in range(2, min(5, len(row))) if pd.notna(row.iloc[col_idx])]
Â  Â  Â  Â  Â  Â  Â  Â  vd_final = ' | '.join(vd_consolidated_parts) if vd_consolidated_parts else None
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  para_value = row.iloc[27] if len(row) > 27 else None

Â  Â  Â  Â  Â  Â  Â  Â  for col_idx in range(5, min(27, len(row))):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cell_content = str(row.iloc[col_idx]).strip()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not cell_content or cell_content.lower() == 'nan':
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  de_category_match = re.search(r'\((.*?)\)', cell_content)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  de_category_val = de_category_match.group(1).strip() if de_category_match else None
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pdv_info_raw = re.sub(r'\s*\([^)]*\)\s*$', '', cell_content).strip()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pdv_info_val = re.sub(r'^\s*(?:\b\w+\s+)?\d+\s*[\|-]\s*', '', pdv_info_raw, 1).strip() if pdv_info_raw else None
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if pdv_info_val or de_category_val:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  processed_records.append({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'DATA': data_value,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'SV': sv_value,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'VD': vd_final,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'PDV': pdv_info_val,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'DE': de_category_val,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'PARA': para_value,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Status': '' 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  })

Â  Â  Â  Â  Â  Â  final_df = pd.DataFrame(processed_records)
Â  Â  Â  Â  Â  Â  return final_df

Â  Â  Â  Â  uploaded_file_1 = st.file_uploader("Envie o arquivo para 'Troca de Canal' (.xlsx)", type=["xlsx"])

Â  Â  Â  Â  if uploaded_file_1 is not None:
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  df_forms = pd.read_excel(uploaded_file_1)
Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("ğŸ“„ Dados Originais (Troca de Canal)")
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(df_forms.head())
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  final_df_forms = transform_google_forms_data(df_forms)
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  output = io.BytesIO()
Â  Â  Â  Â  Â  Â  Â  Â  final_df_forms.to_excel(output, index=False)
Â  Â  Â  Â  Â  Â  Â  Â  output.seek(0)
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  workbook = load_workbook(output)
Â  Â  Â  Â  Â  Â  Â  Â  sheet = workbook.active
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  dropdown_options_excel = '"Aprovado,NÃ£o Aprovado"'
Â  Â  Â  Â  Â  Â  Â  Â  dv = DataValidation(type="list", formula1=dropdown_options_excel, allow_blank=True)
Â  Â  Â  Â  Â  Â  Â  Â  dv.error = 'O valor inserido nÃ£o estÃ¡ na lista.'
Â  Â  Â  Â  Â  Â  Â  Â  dv.errorTitle = 'Valor InvÃ¡lido'
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  col_for_dropdown_letter = get_column_letter(final_df_forms.columns.get_loc('Status') + 1)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  dv.add(f'{col_for_dropdown_letter}2:{col_for_dropdown_letter}{sheet.max_row}')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sheet.add_data_validation(dv)
Â  Â  Â  Â  Â  Â  Â  Â  except KeyError:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("A coluna 'Status' nÃ£o foi encontrada no DataFrame final.")
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  output_with_dropdown = io.BytesIO()
Â  Â  Â  Â  Â  Â  Â  Â  workbook.save(output_with_dropdown)
Â  Â  Â  Â  Â  Â  Â  Â  output_with_dropdown.seek(0)
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("âœ… Dados Transformados (Troca de Canal)")
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(final_df_forms)
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  st.download_button(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label="ğŸ“¥ Baixar Arquivo de Troca de Canal",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data=output_with_dropdown.getvalue(),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_name="troca_canal_processada.xlsx",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Ocorreu um erro durante o processamento de 'Troca de Canal': {e}")

Â  Â  elif script_selection == "Circuito ExecuÃ§Ã£o":
Â  Â  Â  Â  st.write("---")
Â  Â  Â  Â  st.subheader("Circuito ExecuÃ§Ã£o")
Â  Â  Â  Â  st.markdown("Este script converte os valores 'PresenÃ§a' em pontuaÃ§Ã£o, com base no nome das colunas.")

Â  Â  Â  Â  def extract_points(column_name):
Â  Â  Â  Â  Â  Â  """FunÃ§Ã£o para extrair o valor numÃ©rico entre parÃªnteses em uma string de cabeÃ§alho."""
Â  Â  Â  Â  Â  Â  match = re.search(r"\(\s*(\d+)\s*Pontos\s*\)", column_name)
Â  Â  Â  Â  Â  Â  return int(match.group(1)) if match else None

Â  Â  Â  Â  def transform_points_columns(df):
Â  Â  Â  Â  Â  Â  """
Â  Â  Â  Â  Â  Â  Aplica a transformaÃ§Ã£o de 'PresenÃ§a' para pontos nas colunas
Â  Â  Â  Â  Â  Â  que contÃªm 'Pontos' no nome.
Â  Â  Â  Â  Â  Â  """
Â  Â  Â  Â  Â  Â  df_transformed = df.copy()
Â  Â  Â  Â  Â  Â  for col in df_transformed.columns:
Â  Â  Â  Â  Â  Â  Â  Â  if "Pontos" in col:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  points = extract_points(col)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if points is not None:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_transformed[col] = df_transformed[col].apply(lambda x: points if x == "PresenÃ§a" else 0)
Â  Â  Â  Â  Â  Â  return df_transformed

Â  Â  Â  Â  @st.cache_data
Â  Â  Â  Â  def convert_df_to_excel(df):
Â  Â  Â  Â  Â  Â  """Converte DataFrame para um arquivo Excel em memÃ³ria."""
Â  Â  Â  Â  Â  Â  output = io.BytesIO()
Â  Â  Â  Â  Â  Â  with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
Â  Â  Â  Â  Â  Â  Â  Â  df.to_excel(writer, index=False)
Â  Â  Â  Â  Â  Â  processed_data = output.getvalue()
Â  Â  Â  Â  Â  Â  return processed_data

Â  Â  Â  Â  uploaded_file_2 = st.file_uploader("Envie o arquivo para 'Circuito ExecuÃ§Ã£o' (.xlsx)", type=["xlsx"])

Â  Â  Â  Â  if uploaded_file_2 is not None:
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  df_points = pd.read_excel(uploaded_file_2)
Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("ğŸ“„ Dados Originais (Circuito ExecuÃ§Ã£o)")
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(df_points)
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  df_transformed_points = transform_points_columns(df_points)
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("âœ… Dados Transformados (Circuito ExecuÃ§Ã£o)")
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(df_transformed_points)
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  excel_data = convert_df_to_excel(df_transformed_points)
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  st.download_button(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label="ğŸ“¥ Baixar Arquivo de Circuito ExecuÃ§Ã£o Transformado",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data=excel_data,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_name="circuito_execucao_transformado.xlsx",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Ocorreu um erro durante o processamento de 'Circuito ExecuÃ§Ã£o': {e}")
Â  Â  if st.button("Voltar para o InÃ­cio"):
Â  Â  Â  Â  st.session_state['current_page'] = 'home'
Â  Â  Â  Â  st.rerun()

def rh_page():
Â  Â  st.title("Setor de RH")
Â  Â  st.markdown("Bem-vindo(a) ao setor de RH. Abaixo estÃ£o os scripts disponÃ­veis para anÃ¡lise.")

Â  Â  script_choice = st.selectbox(
Â  Â  Â  Â  "Selecione um script para executar:",
Â  Â  Â  Â  ("Selecione...", "Controle de Jornada")
Â  Â  )

Â  Â  st.write("---")

Â  Â  if script_choice == "Controle de Jornada":
Â  Â  Â  Â  st.subheader("Controle de Jornada")
Â  Â  Â  Â  st.markdown("Este script processa uma planilha de controle de jornada e calcula tempos de viagem, dirigibilidade e paradas.")

Â  Â  Â  Â  def format_timedelta_as_hms(td):
Â  Â  Â  Â  Â  Â  if pd.isna(td):
Â  Â  Â  Â  Â  Â  Â  Â  return pd.NaT
Â  Â  Â  Â  Â  Â  total_seconds = td.total_seconds()
Â  Â  Â  Â  Â  Â  hours, remainder = divmod(total_seconds, 3600)
Â  Â  Â  Â  Â  Â  minutes, seconds = divmod(remainder, 60)
Â  Â  Â  Â  Â  Â  return f"{int(hours):02}:{int(minutes):02}:{int(seconds):02}"

Â  Â  Â  Â  def format_timedelta_as_dias_hms(td):
Â  Â  Â  Â  Â  Â  if pd.isna(td):
Â  Â  Â  Â  Â  Â  Â  Â  return pd.NaT
Â  Â  Â  Â  Â  Â  total_seconds = td.total_seconds()
Â  Â  Â  Â  Â  Â  days, remainder = divmod(total_seconds, 86400)
Â  Â  Â  Â  Â  Â  hours, remainder = divmod(remainder, 3600)
Â  Â  Â  Â  Â  Â  minutes, seconds = divmod(remainder, 60)
Â  Â  Â  Â  Â  Â  if days > 0:
Â  Â  Â  Â  Â  Â  Â  Â  return f"{int(days)} dias {int(hours):02}:{int(minutes):02}:{int(seconds):02}"
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  return f"{int(hours):02}:{int(minutes):02}:{int(seconds):02}"

Â  Â  Â  Â  uploaded_file = st.file_uploader("Envie o arquivo 'Controle de Jornada.xlsx'", type=["xlsx"])

Â  Â  Â  Â  if uploaded_file is not None:
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  df = pd.read_excel(uploaded_file)
Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("ğŸ“„ Dados Originais")
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(df.head())
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  all_events = []
Â  Â  Â  Â  Â  Â  Â  Â  for index, row in df.iterrows():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  motorista = row.get('Motorista')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  timestamp_str = row.get('Carimbo de data/hora')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if pd.isna(timestamp_str) or pd.isna(motorista):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  timestamp = pd.to_datetime(timestamp_str)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  entry_type = row.get('Qual o tipo de lanÃ§amento?')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if entry_type == 'Inicio Jornada':
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  date_str = row.get('Dia')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  time_str = row.get('HorÃ¡rio')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if pd.notna(date_str) and pd.notna(time_str):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  start_time = pd.to_datetime(f"{date_str} {time_str}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_events.append({'Motorista': motorista, 'Tipo de LanÃ§amento': entry_type, 'Inicio': start_time, 'Fim': None, 'Motivo': None, 'Carimbo de data/hora': timestamp})
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif entry_type == 'Inicio de Viagem':
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  date_str = row.get('Dia.1')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  time_str = row.get('HorÃ¡rio.1')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if pd.notna(date_str) and pd.notna(time_str):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  start_time = pd.to_datetime(f"{date_str} {time_str}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_events.append({'Motorista': motorista, 'Tipo de LanÃ§amento': entry_type, 'Inicio': start_time, 'Fim': None, 'Motivo': None, 'Carimbo de data/hora': timestamp})
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif entry_type == 'Fim da Viagem':
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  time_str = row.get('Fim.5')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if pd.notna(time_str):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  time_str = str(time_str).split(' ')[-1]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  end_time = pd.to_datetime(f"{timestamp.strftime('%Y-%m-%d')} {time_str}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_events.append({'Motorista': motorista, 'Tipo de LanÃ§amento': entry_type, 'Inicio': None, 'Fim': end_time, 'Motivo': None, 'Carimbo de data/hora': timestamp})
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif entry_type == 'Fim de Jornada':
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  date_str = row.get('Dia.2')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  time_str = row.get('HorÃ¡rio.3')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if pd.notna(date_str) and pd.notna(time_str):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  end_time = pd.to_datetime(f"{date_str} {time_str}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_events.append({'Motorista': motorista, 'Tipo de LanÃ§amento': entry_type, 'Inicio': None, 'Fim': end_time, 'Motivo': None, 'Carimbo de data/hora': timestamp})
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  parada_cols_map = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  '1': {'inicio': 'Inicio ', 'fim': 'Fim', 'motivo': 'Motivo'},
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  '2': {'inicio': 'Inicio', 'fim': 'Fim.1', 'motivo': 'Motivo.1'},
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  '3': {'inicio': 'Inicio.1', 'fim': 'Fim.2', 'motivo': 'Motivo.2'},
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  '4': {'inicio': 'Inicio.2', 'fim': 'Fim.3', 'motivo': 'Motivo.3'},
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  '5': {'inicio': 'Inicio.3', 'fim': 'Fim.4', 'motivo': 'Motivo.4'}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for i in range(1, 6):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cols = parada_cols_map.get(str(i))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  start_time_str = row.get(cols['inicio'])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  end_time_str = row.get(cols['fim'])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  motivo = row.get(cols['motivo'])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if pd.notna(start_time_str) and pd.notna(end_time_str) and pd.notna(motivo):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  date_str = timestamp.strftime('%Y-%m-%d')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  start_time_str = str(start_time_str).split(' ')[-1]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  end_time_str = str(end_time_str).split(' ')[-1]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  start_time = pd.to_datetime(f"{date_str} {start_time_str}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  end_time = pd.to_datetime(f"{date_str} {end_time_str}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_events.append({'Motorista': motorista, 'Tipo de LanÃ§amento': f'Parada {i}', 'Inicio': start_time, 'Fim': end_time, 'Motivo': motivo, 'Carimbo de data/hora': timestamp})
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except ValueError:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Erro ao converter data/hora na linha {index} para 'Parada {i}'.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df = pd.DataFrame(all_events)
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df.dropna(subset=['Motorista', 'Tipo de LanÃ§amento'], how='all', inplace=True)
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df.sort_values(by=['Motorista', 'Carimbo de data/hora'], inplace=True)
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df.reset_index(drop=True, inplace=True)
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df['Tempo Total de Jornada'] = pd.NaT
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df['Tempo Total de Viagem'] = pd.NaT
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df['Tempo de Dirigibilidade'] = pd.NaT
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df['Tempo AlmoÃ§o'] = pd.NaT
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df['Tempo Carga/Descarga'] = pd.NaT
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df['Tempo LiberaÃ§Ã£o N.F.'] = pd.NaT
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df['Tempo Repouso'] = pd.NaT
Â  Â  Â  Â  Â  Â  Â  Â  for (motorista, dia), group in consolidated_df.groupby(['Motorista', consolidated_df['Carimbo de data/hora'].dt.date]):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  inicio_jornada = group[group['Tipo de LanÃ§amento'] == 'Inicio Jornada']['Inicio'].min()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fim_jornada = group[group['Tipo de LanÃ§amento'] == 'Fim de Jornada']['Fim'].max()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tempo_jornada = fim_jornada - inicio_jornada if pd.notnull(inicio_jornada) and pd.notnull(fim_jornada) else timedelta(seconds=0)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  inicio_viagem = group[group['Tipo de LanÃ§amento'] == 'Inicio de Viagem']['Inicio'].min()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  fim_viagem = group[group['Tipo de LanÃ§amento'] == 'Fim da Viagem']['Fim'].max()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tempo_viagem = fim_viagem - inicio_viagem if pd.notnull(inicio_viagem) and pd.notnull(fim_viagem) else timedelta(seconds=0)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break_durations = group.dropna(subset=['Motivo']).copy()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not break_durations.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break_durations['Duration'] = break_durations['Fim'] - break_durations['Inicio']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  break_durations['Duration'] = timedelta(seconds=0)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  almoco_duration = break_durations[break_durations['Motivo'] == 'AlmoÃ§o']['Duration'].sum()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  carga_descarga_duration = break_durations[break_durations['Motivo'] == 'Carga/Descarga']['Duration'].sum()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  liberacao_nf_duration = break_durations[break_durations['Motivo'] == 'LiberaÃ§Ã£o de N.F']['Duration'].sum()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  repouso_duration = break_durations[break_durations['Motivo'] == 'Repouso']['Duration'].sum()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  total_stop_time = almoco_duration + carga_descarga_duration + liberacao_nf_duration + repouso_duration
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tempo_dirigibilidade = tempo_viagem - total_stop_time
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df.loc[group[group['Tipo de LanÃ§amento'] == 'Fim de Jornada'].index, 'Tempo Total de Jornada'] = tempo_jornada
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df.loc[group[group['Tipo de LanÃ§amento'] == 'Fim da Viagem'].index, 'Tempo Total de Viagem'] = tempo_viagem
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df.loc[group[group['Tipo de LanÃ§amento'] == 'Fim da Viagem'].index, 'Tempo de Dirigibilidade'] = tempo_dirigibilidade
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df.loc[group[group['Motivo'] == 'AlmoÃ§o'].index, 'Tempo AlmoÃ§o'] = almoco_duration
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df.loc[group[group['Motivo'] == 'Carga/Descarga'].index, 'Tempo Carga/Descarga'] = carga_descarga_duration
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df.loc[group[group['Motivo'] == 'LiberaÃ§Ã£o de N.F'].index, 'Tempo LiberaÃ§Ã£o N.F.'] = liberacao_nf_duration
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df.loc[group[group['Motivo'] == 'Repouso'].index, 'Tempo Repouso'] = repouso_duration
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df['Tempo Total de Jornada'] = consolidated_df['Tempo Total de Jornada'].apply(format_timedelta_as_dias_hms)
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df['Tempo Total de Viagem'] = consolidated_df['Tempo Total de Viagem'].apply(format_timedelta_as_dias_hms)
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df['Tempo de Dirigibilidade'] = consolidated_df['Tempo de Dirigibilidade'].apply(format_timedelta_as_hms)
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df['Tempo AlmoÃ§o'] = consolidated_df['Tempo AlmoÃ§o'].apply(format_timedelta_as_hms)
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df['Tempo Carga/Descarga'] = consolidated_df['Tempo Carga/Descarga'].apply(format_timedelta_as_hms)
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df['Tempo LiberaÃ§Ã£o N.F.'] = consolidated_df['Tempo LiberaÃ§Ã£o N.F.'].apply(format_timedelta_as_hms)
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df['Tempo Repouso'] = consolidated_df['Tempo Repouso'].apply(format_timedelta_as_hms)
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df.drop(columns=['Carimbo de data/hora'], inplace=True)
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("âœ… Dados Processados")
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(consolidated_df)
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  excel_data = io.BytesIO()
Â  Â  Â  Â  Â  Â  Â  Â  consolidated_df.to_excel(excel_data, sheet_name="Dados Consolidados", index=False)
Â  Â  Â  Â  Â  Â  Â  Â  excel_data.seek(0)
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  st.download_button(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label="ğŸ“¥ Baixar Arquivo Processado",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data=excel_data,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_name="Jornada_Calculo.xlsx",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Ocorreu um erro ao processar o arquivo: {e}")

Â  Â  if st.button("Voltar para o InÃ­cio"):
Â  Â  Â  Â  st.session_state['current_page'] = 'home'
Â  Â  Â  Â  st.rerun()
def site_page():
Â  Â  st.title("Setor SÃ­tio")
Â  Â  st.markdown("Bem-vindo(a) ao setor SÃ­tio. Abaixo estÃ£o os scripts disponÃ­veis para anÃ¡lise.")
Â  Â  
Â  Â  script_choice = st.selectbox(
Â  Â  Â  Â  "Selecione um script para executar:",
Â  Â  Â  Â  ("Selecione...", "SÃ­tio Santa Izabel")
Â  Â  )

Â  Â  st.write("---")

Â  Â  if script_choice == "SÃ­tio Santa Izabel":
Â  Â  Â  Â  st.subheader("SÃ­tio Santa Izabel")
Â  Â  Â  Â  st.markdown("Este script processa a planilha de controle do SÃ­tio Santa Izabel e a divide em abas com base nos lanÃ§amentos.")

Â  Â  Â  Â  def normalize_columns(columns_list):
Â  Â  Â  Â  Â  Â  """
Â  Â  Â  Â  Â  Â  Normaliza uma lista de nomes de colunas, removendo espaÃ§os extras,
Â  Â  Â  Â  Â  Â  caracteres especiais e quebras de linha.
Â  Â  Â  Â  Â  Â  """
Â  Â  Â  Â  Â  Â  normalized_list = []
Â  Â  Â  Â  Â  Â  for col in columns_list:
Â  Â  Â  Â  Â  Â  Â  Â  col = re.sub(r'\s+', ' ', col).strip()
Â  Â  Â  Â  Â  Â  Â  Â  col = col.replace('\n', ' ')
Â  Â  Â  Â  Â  Â  Â  Â  normalized_list.append(col)
Â  Â  Â  Â  Â  Â  return normalized_list

Â  Â  Â  Â  uploaded_file = st.file_uploader("Envie o arquivo 'SÃTIO SANTA IZABEL.xlsx'", type=["xlsx"])

Â  Â  Â  Â  if uploaded_file is not None:
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  df = pd.read_excel(uploaded_file, engine='openpyxl')
Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("ğŸ“„ Dados Originais")
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(df.head())

Â  Â  Â  Â  Â  Â  Â  Â  df.columns = normalize_columns(df.columns)

Â  Â  Â  Â  Â  Â  Â  Â  planilhas_config = {
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'PulverizaÃ§Ã£o': [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Carimbo de data/hora', 'Qual lanÃ§amento', 'Qual TalhÃ£o?',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'DiagnÃ³stico e Justificativa', 'Fase FenolÃ³gica', 'PrevisÃ£o colheita',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Problema Alvo (Praga, DoenÃ§a, Planta Daninha ou DeficiÃªncia Nutricional)',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'DiagnÃ³stico e NÃ­vel de InfestaÃ§Ã£o/OcorrÃªncia (DescriÃ§Ã£o detalhada)',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Justificativa TÃ©cnica para a RecomendaÃ§Ã£o',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'PRODUTO (N.C*E I.A.**)','Volume de Calda Recomendado (L/ha)',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Equipamento de aplicaÃ§Ã£o', 'NÃºmero de AplicaÃ§Ãµes Recomendadas',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Intervalo entre AplicaÃ§Ãµes (dias - se houver mais de uma)', 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Modo de AplicaÃ§Ã£o','Ã‰poca/EstÃ¡dio de AplicaÃ§Ã£o',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Intervalo de SeguranÃ§a/PerÃ­odo de CarÃªncia (dias)',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Intervalo de Reentrada na Ãrea (horas)',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Equipamento de ProteÃ§Ã£o Individual (EPI)',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'CondiÃ§Ãµes ClimÃ¡ticas Ideais para AplicaÃ§Ã£o ex: "Evitar ventos acima de 10 km/h, temperatura abaixo de 30Â°C, umidade relativa acima de 55%"',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Cuidados com a Calda e Descarte de Embalagens ex: "Realizar trÃ­plice lavagem das embalagens e descartÃ¡-las em locais indicados"',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'InformaÃ§Ãµes sobre Mistura em Tanque (se aplicÃ¡vel)',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'ObservaÃ§Ãµes Adicionais/AdvertÃªncias',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Controle de IrrigaÃ§Ã£o': [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Carimbo de data/hora', 'Qual lanÃ§amento', 'PerÃ­odo', 'Setor/TalhÃ£o', 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Hora(s) de irrigaÃ§Ã£o', 'Volume de Ãgua (L)', 'Tipo de IrrigaÃ§Ã£o',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'ObservaÃ§Ãµes (Clima/Outros)', 'ResponsÃ¡vel', 'PrÃ³xima IrrigaÃ§Ã£o Sugerida'
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Controle de Pragas': [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Carimbo de data/hora', 'Qual lanÃ§amento', 'DATA (3)', 'PRAGA', 'RECOMENDAÃ‡ÃƒO',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'RECEITA', 'MODO DE APLICAÃ‡ÃƒO', 'PERÃODO', 'OBSERVAÃ‡ÃƒO'
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'PluviÃ´metro - (somente em dias de chuva)': [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Carimbo de data/hora', 'Qual lanÃ§amento', 'DATA (1)', 'LEITURA(MM)', 'OBSERVAÃ‡Ã•ES'
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'HidrÃ´metro': [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Carimbo de data/hora', 'Qual lanÃ§amento', 'DATA (2)', 'LEITURA (mÂ³)'
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Lavagem de EPIs': [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Carimbo de data/hora', 'Qual lanÃ§amento', 'Data da Lavagem:', 'ResponsÃ¡vel pela Lavagem ',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Local da Lavagem', 'EPI', 'Agente de Limpeza Utilizado:', 'Temperatura da Ãgua', 'Ciclos de enxague',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'CondiÃ§Ãµes de Armazenamento'
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Registro de aplicaÃ§Ãµes': [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Carimbo de data/hora', 'Qual lanÃ§amento', 'Cultura e/ou Variedade Tratada',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Local da AplicaÃ§Ã£o ( Por favor, especifique a zona geogrÃ¡fica, nome/referÃªncia da exploraÃ§Ã£o, e o campo de produÃ§Ã£o, pomar, estufa ou instalaÃ§Ã£o onde a cultura se encontra.)',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Data de InÃ­cio da AplicaÃ§Ã£o',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Data de Fim da AplicaÃ§Ã£o',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Nome Comercial Registrado do Produto',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Intervalo de SeguranÃ§a PrÃ©-Colheita (PHS)',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Quantidade de Produto Aplicado',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'ConcentraÃ§Ã£o ou FrequÃªncia',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Nome Completo do Aplicador',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Nome Completo da Pessoa Tecnicamente ResponsÃ¡vel',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Limpeza do Local': [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Carimbo de data/hora', 'Qual lanÃ§amento', 'LOCAL', 'Marque com "X" a opÃ§Ã£o que melhor descreve o estado de limpeza [PISOS]',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Marque com "X" a opÃ§Ã£o que melhor descreve o estado de limpeza [LIXEIRAS]', 'Marque com "X" a opÃ§Ã£o que melhor descreve o estado de limpeza [SuperfÃ­cies (mesas, bancadas)]',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Marque com "X" a opÃ§Ã£o que melhor descreve o estado de limpeza [Janelas e vidros]', 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Marque com "X" a opÃ§Ã£o que melhor descreve o estado de limpeza [Banheiros]', 'Marque com "X" a opÃ§Ã£o que melhor descreve o estado de limpeza [Descarte de resÃ­duos]',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Marque com "X" a opÃ§Ã£o que melhor descreve o estado de limpeza [OrganizaÃ§Ã£o geral]',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Problemas encontrados', 'SugestÃµes para melhoria'
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Limpeza dos Equipamentos e Dispositivos': [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'Qual a Limpeza (7)', 'Data da Lavagem (7)', 'Item Lavado (7)', 'Produto Utilizado (7)', 'Procedimento de Lavagem (Exemplo "submersÃ£o" , "prÃ©-lavagem") (7)',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'ResponsÃ¡vel pela Lavagem (7)', 'ObservaÃ§Ãµes (7)' 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  output = io.BytesIO()
Â  Â  Â  Â  Â  Â  Â  Â  with pd.ExcelWriter(output, engine='openpyxl') as writer:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for sheet_name, columns in planilhas_config.items():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  normalized_columns = normalize_columns(columns)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if sheet_name == 'PulverizaÃ§Ã£o':
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for col in df.columns:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if re.search(r'\(\d+\)', col) and col not in ['DATA (1)', 'DATA (2)', 'DATA (3)']:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  normalized_columns.append(col)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  normalized_columns = list(dict.fromkeys(normalized_columns))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_filtered = df[df['Qual lanÃ§amento'] == sheet_name]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  existing_columns = [col for col in normalized_columns if col in df_filtered.columns]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_sheet = df_filtered[existing_columns]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_sheet.to_excel(writer, sheet_name=sheet_name, index=False)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info(f"Aba '{sheet_name}' criada com sucesso.")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  except KeyError as e:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"Aviso: Ocorreu um erro ao filtrar a aba '{sheet_name}'. Verifique se o nome da aba estÃ¡ correto.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  output.seek(0)
Â  Â  Â  Â  Â  Â  Â  Â  st.subheader("âœ… Processo ConcluÃ­do")
Â  Â  Â  Â  Â  Â  Â  Â  st.success("O arquivo foi processado e estÃ¡ pronto para download.")
Â  Â  Â  Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  Â  Â  Â  st.download_button(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label="ğŸ“¥ Baixar Arquivo Processado",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data=output,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_name="sitio_santaizabel.xlsx",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"Ocorreu um erro ao processar o arquivo: {e}")
Â  Â  
Â  Â  if st.button("Voltar para o InÃ­cio"):
Â  Â  Â  Â  st.session_state['current_page'] = 'home'
Â  Â  Â  Â  st.rerun()

# LÃ³gica principal da pÃ¡gina
if 'is_logged_in' not in st.session_state:
Â  Â  st.session_state['is_logged_in'] = False
if 'current_page' not in st.session_state:
Â  Â  st.session_state['current_page'] = 'login'
if 'LOGIN_INFO' not in st.session_state:
Â  Â  st.session_state['LOGIN_INFO'] = {
Â  Â  Â  Â  "admin": "Joao789",
Â  Â  Â  Â  "amanda": "12345",
Â  Â  Â  Â  "marcia": "54321"
Â  Â  }

# ConfiguraÃ§Ãµes iniciais da pÃ¡gina
st.set_page_config(
Â  Â  page_title="Lince Distribuidora de Bebidas - Login",
Â  Â  page_icon="ğŸ ",
Â  Â  layout="centered"
)

# Adiciona CSS personalizado para um visual mais limpo e profissional
st.markdown("""
<style>
Â  Â  .stApp {
Â  Â  Â  Â  background-color: #f0f2f6;
Â  Â  }
Â  Â  div.stButton > button:first-child {
Â  Â  Â  Â  background-color: #007bff;
Â  Â  Â  Â  color: white;
Â  Â  Â  Â  border-radius: 5px;
Â  Â  Â  Â  padding: 10px 20px;
Â  Â  Â  Â  border: none;
Â  Â  Â  Â  box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
Â  Â  }
Â  Â  div.stButton > button:first-child:hover {
Â  Â  Â  Â  background-color: #0056b3;
Â  Â  Â  Â  transform: translateY(-2px);
Â  Â  Â  Â  box-shadow: 0 6px 8px rgba(0, 0, 0, 0.15);
Â  Â  }
Â  Â  .stTextInput label, .stForm > div > div > label {
Â  Â  Â  Â  font-weight: bold;
Â  Â  Â  Â  color: #333;
Â  Â  }
Â  Â  .stTitle {
Â  Â  Â  Â  text-align: center;
Â  Â  Â  Â  color: #004d99;
Â  Â  Â  Â  font-family: 'Arial Black', sans-serif;
Â  Â  }
Â  Â  .st-emotion-cache-1c7y3q { /* CSS para o container do formulÃ¡rio */
Â  Â  Â  Â  background-color: #F8F8F8;
Â  Â  Â  Â  padding: 30px;
Â  Â  Â  Â  border-radius: 10px;
Â  Â  Â  Â  box-shadow: 0 8px 16px rgba(0, 0, 0, 0.1);
Â  Â  }
Â  Â  .centered-icon {
Â  Â  Â  Â  text-align: center;
Â  Â  Â  Â  font-size: 5rem;
Â  Â  }
Â  Â  .app-card {
Â  Â  Â  Â  background-color: #fff;
Â  Â  Â  Â  padding: 20px;
Â  Â  Â  Â  border-radius: 10px;
Â  Â  Â  Â  box-shadow: 0 4px 8px rgba(0,0,0,0.1);
Â  Â  Â  Â  text-align: center;
Â  Â  Â  Â  margin-bottom: 20px;
Â  Â  Â  Â  cursor: pointer;
Â  Â  Â  Â  transition: transform 0.2s;
Â  Â  Â  Â  height: 100%;
Â  Â  }
Â  Â  .app-card:hover {
Â  Â  Â  Â  transform: translateY(-5px);
Â  Â  }
Â  Â  .app-card h3 {
Â  Â  Â  Â  color: #004d99;
Â  Â  Â  Â  font-size: 1.2rem;
Â  Â  }
Â  Â  .app-card p {
Â  Â  Â  Â  color: #555;
Â  Â  Â  Â  font-size: 0.9rem;
Â  Â  }
Â  Â  .st-emotion-cache-1f81n9p a { /* Estilo para o link do botÃ£o para parecer um card */
Â  Â  Â  Â  text-decoration: none;
Â  Â  Â  Â  color: inherit;
Â  Â  }
</style>
""", unsafe_allow_html=True)

if st.session_state.get('is_logged_in', False):
Â  Â  page_functions = {
Â  Â  Â  Â  'home': main_page,
Â  Â  Â  Â  'logistics': logistics_page,
Â  Â  Â  Â  'commercial': commercial_page,
Â  Â  Â  Â  'rh': rh_page,
Â  Â  Â  Â  'site': site_page
Â  Â  }
Â  Â  page_functions.get(st.session_state.get('current_page', 'home'), main_page)()
else:
Â  Â  login_form()
